{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ6cc4Qmjl+N2an0WEAWwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Conversation-AI-System-using-LLMs-on-E-commerce-Data/blob/main/Finetune_BERT_for_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TUQqus-2cHJA"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install imbalanced-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLJ-JmFM0gMe",
        "outputId": "41ba7b81-aee8-4b05-d8af-b5723dd2ad49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9mdcy34e0gPT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoModel, BertTokenizerFast, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Load DataFrame\n",
        "df = pd.read_csv(\"./updated_data9thFeb.csv\")\n",
        "df = df[['review_content', 'Sentiment']]\n",
        "\n",
        "# Define a mapping function\n",
        "sentiment_mapping = {'Positive': 2, 'Negative': 0, 'Neutral': 1}\n",
        "df['Sentiment'] = df['Sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "max_length = 1400\n",
        "df = df[df['review_content'].apply(lambda x: len(x) <= max_length)]\n",
        "\n",
        "print(f'Original dataset shape: {Counter(df[\"Sentiment\"])}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8GK495wZMwA",
        "outputId": "d0f1608e-f5a2-4d7d-f68a-0ed504a75d55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: Counter({2: 454, 0: 71, 1: 40})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split into train, validation, and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['review_content'], df['Sentiment'],\n",
        "                                                                    random_state=2021,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['Sentiment'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2021,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "EyVYnlAubvVr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Import BERT-base pretrained model and tokenizer\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "oQY4gnIGbxwv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BF9rWRkeckEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens=[len(i.split()) for i in df.review_content]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(lens)\n"
      ],
      "metadata": {
        "id": "u-thAzh-cfTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "7dd640a3-9264-42d4-9eb7-35496f5d328c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([76., 90., 73., 76., 79., 24., 54., 43., 21., 29.]),\n",
              " array([ 11. ,  34.5,  58. ,  81.5, 105. , 128.5, 152. , 175.5, 199. ,\n",
              "        222.5, 246. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Tokenize and encode sequences\n",
        "pad_len = 512\n",
        "tokens_train = tokenizer.batch_encode_plus(train_text.tolist(), max_length=pad_len, pad_to_max_length=True, truncation=True)\n",
        "tokens_val = tokenizer.batch_encode_plus(val_text.tolist(), max_length=pad_len, pad_to_max_length=True, truncation=True)\n",
        "tokens_test = tokenizer.batch_encode_plus(test_text.tolist(), max_length=pad_len, pad_to_max_length=True, truncation=True)\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "GG-uzhI6byjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "HhSyNh2gb1aE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the BERT architecture\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "rnHCph33b7eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sentiment classification model\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes=3):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "        x = self.fc1(cls_hs)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model = SentimentClassifier(bert, num_classes=3)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "kzJeOcNocCYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels)\n",
        "weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "cross_entropy = nn.NLLLoss(weight=weights)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY1lMcVc0gSF",
        "outputId": "5cff015f-40e4-44b2-83d5-a4633d27618a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Number of training epochs\n",
        "epochs = 1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        model.zero_grad()\n",
        "        preds = model(sent_id, mask)\n",
        "        loss = cross_entropy(preds, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "HejzA1li0gxf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        preds = model(sent_id, mask)\n",
        "        all_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds, axis=0)\n",
        "pred_labels = np.argmax(all_preds, axis=1)\n",
        "\n",
        "print(classification_report(val_y.numpy(), pred_labels, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W1FV-bA1Fzu",
        "outputId": "306f4346-e0fa-495c-cd67-0b49cfddc576"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00        10\n",
            "           1       1.00      0.00      0.00         6\n",
            "           2       0.81      1.00      0.90        69\n",
            "\n",
            "    accuracy                           0.81        85\n",
            "   macro avg       0.94      0.33      0.30        85\n",
            "weighted avg       0.85      0.81      0.73        85\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-uHrlKQgZVzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}